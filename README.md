
# ğŸš€ Wellness Tourism â€“ End-to-End MLOps Pipeline

### **Automated Data â†’ Model â†’ Deployment Pipeline using GitHub Actions, MLflow & Hugging Face**

This repository contains a complete **MLOps workflow** for building, training, tracking, and deploying a **Wellness Tourism Recommendation Model**.
The project automates:

* ğŸ“¥ Dataset registration to Hugging Face
* ğŸ§¹ Data preprocessing
* ğŸ¤– Model training with MLflow tracking
* ğŸ“¦ Model & artifact upload
* ğŸŒ Deployment to Hugging Face Space

Everything runs automatically using **GitHub Actions CI/CD**.

---

## ğŸ§  Project Overview

The goal is to build a model that analyzes **tourism data** and predicts patterns related to wellness travel.
We track the entire pipeline using MLflow and deploy the final model for real-time usage.

---

# ğŸ”§ Tech Stack

| Layer                   | Technologies                 |
| ----------------------- | ---------------------------- |
| **ML Code**             | Python, Pandas, Scikit-Learn |
| **Experiment Tracking** | MLflow                       |
| **Model Registry**      | Hugging Face Hub             |
| **Deployment**          | Hugging Face Space           |
| **CI/CD**               | GitHub Actions               |
| **Orchestration**       | Multi-stage Workflow Jobs    |

---

# ğŸ“‚ Project Structure

```
Wellness-Tourism-MLOps/
â”‚
â”œâ”€â”€ mlops/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ tourism.csv              # Dataset
â”‚   â”‚
â”‚   â”œâ”€â”€ model_building/
â”‚   â”‚   â”œâ”€â”€ data_register.py         # Upload dataset to HF Hub
â”‚   â”‚   â”œâ”€â”€ prep.py                  # Data preprocessing
â”‚   â”‚   â”œâ”€â”€ train.py                 # ML model training & logging
â”‚   â”‚
â”‚   â”œâ”€â”€ deployment/
â”‚   â”‚   â””â”€â”€ hosting.py               # Push app to Hugging Face Space
â”‚   â”‚
â”‚   â”œâ”€â”€ requirements.txt             # Dependencies
â”‚
â”œâ”€â”€ .github/workflows/
â”‚   â””â”€â”€ mlops_pipeline.yml           # CI/CD pipeline automation
â”‚
â””â”€â”€ README.md
```

---

# âš™ï¸ MLOps Pipeline (GitHub Actions)

This project uses a **4-stage CI/CD pipeline**:

---

## **ğŸŸ¦ 1. Dataset Registration**

Uploads dataset â†’ Hugging Face Datasets repo

Script:

```
python mlops/model_building/data_register.py
```

---

## **ğŸŸ© 2. Data Preparation**

Cleans & transforms the dataset.

Script:

```
python mlops/model_building/prep.py
```

---

## **ğŸŸ§ 3. Model Training**

* Trains ML model
* Logs metrics to MLflow
* Saves model artifacts
* Uploads final model to Hugging Face

Script:

```
python mlops/model_building/train.py
```

---

## **ğŸŸª 4. Deployment**

Pushes frontend + model to Hugging Face Space.

Script:

```
python mlops/hosting/hosting.py
```

---

# ğŸ” GitHub Secrets Required

Go to:

**GitHub Repo â†’ Settings â†’ Secrets & Variables â†’ Actions**

Add:

| Secret Name | Value                                             |
| ----------- | ------------------------------------------------- |
| `HF_TOKEN`  | Your Hugging Face Access Token (write permission) |

---

# â–¶ï¸ How to Run Locally

### **1. Clone the repo**

```bash
git clone https://github.com/<your-username>/Wellness-Tourism-MLOps.git
cd Wellness-Tourism-MLOps
```

### **2. Install dependencies**

```bash
pip install -r mlops/requirements.txt
```

### **3. Run the pipeline manually**

```bash
python mlops/model_building/data_register.py
python mlops/model_building/prep.py
python mlops/model_building/train.py
python mlops/hosting/hosting.py
```

---

# ğŸ“Š MLflow Tracking

During training:

* Experiments
* Runs
* Parameters
* Metrics (Accuracy, F1, etc.)
* Artifacts (model, plots)

are automatically logged.

---

# ğŸŒ Deployment

The final application is deployed to Hugging Face Space:

```
https://huggingface.co/spaces/<username>/<space-name>
```

From here, users can interact with the trained model.

---

# ğŸ§ª Model Output

âœ” Cleaned dataset
âœ” Trained ML model
âœ” Evaluation metrics
âœ” UI/Hosted demo
âœ” Hugging Face model card
âœ” Versioned ML artifacts

---

# ğŸ›  Troubleshooting

### âŒ â€œdataset repo not foundâ€

Fix:

* Create dataset repo on HF
* Use same username in script
* Ensure your token has **write access**

### âŒ â€œ403 â€” permission deniedâ€

Fix:

* Regenerate token
* Make sure you saved it as `HF_TOKEN`
* Token must start with `hf_` or `github_pat_` depending on platform

---

# ğŸ™Œ Acknowledgements

This project uses:

* ğŸ¯ Hugging Face Hub
* ğŸ¯ MLflow
* ğŸ¯ GitHub Actions
* ğŸ¯ Python ML ecosystem

